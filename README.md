# SafeGen
Prevent deepfakes. Block impersonation. Protect brand identity. SafeGen is an AI safety gateway that wraps around any generative model to detect, restrict, and log harmful or unauthorized content.

# SafeGen â€“ Ethical AI Guardrails for Prompts and Content

**SafeGen** is a security-focused AI middleware platform that protects against harmful or unauthorized generation of AI content (text, images, video) involving real people, brands, or sensitive assets.



# Step 1: Define the Core Pipeline
- We'll implement a module that:

- Takes a user prompt.

- Converts it into embeddings (e.g., using xlm-roberta-base).

- Passes embeddings through a neural network classifier.

- Returns:

- "safe" â†’ forwards to RAG module (future step),

- "unsafe" â†’ returns a restricted message.

## ğŸ” What It Does

-  Blocks harmful prompts (e.g., impersonation, fake news, deepfakes)
-  Filters unauthorized requests based on company-registered data
-  Allows only safe, ethical generation of content
-  Offers companies a dashboard to register their assets and protect them from misuse


##  File Structure (Phase 1)
SafeGen/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ prompt_guard.py  â† [We're building this now]
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py          â† [Calls `prompt_guard.py`]
â”œâ”€â”€ model/
â”‚   â””â”€â”€ classifier.pt    â† [Pretrained safe/unsafe classifier]
â”œâ”€â”€ data/
â”‚   â””â”€â”€ prompts.json     â† [sample prompts for test]
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md



        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ User Promptâ”‚
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Embedding Layerâ”‚  â† xlm-roberta / BERT
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ Reward Model (DPO)     â”‚  â† Predict if safe or unsafe
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“            â†“
     [Safe]        [Unsafe]
      â†“                â†“
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  LLM   â”‚       â”‚ Blocked Msg  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## ğŸš€ Use Cases

| User | Use Case |
|------|----------|
| LLM App Developer | Integrate SafeGen API to reject bad prompts |
| AI Video/Photo Tool | Prevent generation of celebrity or brand-based fakes |
| Brand/Company | Protect CEO faces, logos, product blueprints from being used |
| Schools | Prevent students from generating offensive or impersonating content |

## ğŸ§  Components

- `prompt_guard.py` â€“ Blocks prompts with harmful intent
- `output_filter.py` *(coming soon)* â€“ Detects post-generation risks
- `consent_registry.py` *(coming soon)* â€“ Tracks allowed brands/assets
- `api/` â€“ FastAPI server to interact with SafeGen
- `frontend/` *(planned)* â€“ Dashboard for companies

## ğŸ’¡ Business Model (SaaS)

- Free for personal / dev use (limited)
- Paid plans for companies to:
  - Register assets
  - Access misuse reports
  - Integrate via API keys

## ğŸ›  Tech Stack

- Python, FastAPI
- Regex + LLM-based filtering
- GitHub Actions (CI)
- Vision model (for image scan) *(planned)*
- Stripe billing *(planned)*

---

## ğŸ“‚ Project Structure

SafeGen/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ prompt_guard.py
â”‚ â”œâ”€â”€ consent_registry.py # (to build)
â”‚ â”œâ”€â”€ output_filter.py # (to build)
â”‚
â”œâ”€â”€ api/
â”‚ â””â”€â”€ main.py # FastAPI server
â”‚
â”œâ”€â”€ frontend/ # Streamlit or ReactJS dashboard (future)
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt